{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4 Model Evaluation\n",
    "In this notebook, we will compare the results of the base Wav2Vec2 model and our finetuned model. We will use WER and CER as the evaluation metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from jiwer import wer, cer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transcribe the evaluation dataset using the finetuned model. The transcription using the base model was already performed in Task 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcriptions have been added to the CSV file.\n"
     ]
    }
   ],
   "source": [
    "# Use cv-decode.py to transcribe the audio using the fine-tuned model\n",
    "!python ../asr/cv-decode.py ../data/common_voice/cv-valid-dev.csv ../data/common_voice/cv-valid-dev/ ../task-4/transcribed_data-ft.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Base Model</th>\n",
       "      <th>Fine-Tuned Model</th>\n",
       "      <th>Improvement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Word Error Rate (WER)</td>\n",
       "      <td>0.108120</td>\n",
       "      <td>0.078751</td>\n",
       "      <td>0.029369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Character Error Rate (CER)</td>\n",
       "      <td>0.045444</td>\n",
       "      <td>0.034017</td>\n",
       "      <td>0.011427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Metric  Base Model  Fine-Tuned Model  Improvement\n",
       "0       Word Error Rate (WER)    0.108120          0.078751     0.029369\n",
       "1  Character Error Rate (CER)    0.045444          0.034017     0.011427"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV files for both models\n",
    "base_model_results_path = '../asr/transcribed_data.csv'\n",
    "finetuned_model_results_path = 'transcribed_data-ft.csv'\n",
    "\n",
    "base_data = pd.read_csv(base_model_results_path)\n",
    "finetuned_data = pd.read_csv(finetuned_model_results_path)\n",
    "\n",
    "# Extract the ground truth (text) and generated transcriptions\n",
    "base_actual_labels = base_data['text']\n",
    "base_generated_text = base_data['generated_text']\n",
    "\n",
    "finetuned_actual_labels = finetuned_data['text']\n",
    "finetuned_generated_text = finetuned_data['generated_text']\n",
    "\n",
    "# Convert elements to strings\n",
    "base_actual_labels = [str(label) for label in base_actual_labels]\n",
    "base_generated_text = [str(label) for label in base_generated_text]\n",
    "\n",
    "finetuned_actual_labels = [str(label) for label in finetuned_actual_labels]\n",
    "finetuned_generated_text = [str(label) for label in finetuned_generated_text]\n",
    "\n",
    "# Convert both actual labels and generated text to lowercase\n",
    "base_actual_labels = [label.lower() for label in base_actual_labels]\n",
    "base_generated_text = [text.lower() for text in base_generated_text]\n",
    "\n",
    "finetuned_actual_labels = [label.lower() for label in finetuned_actual_labels]\n",
    "finetuned_generated_text = [text.lower() for text in finetuned_generated_text]\n",
    "\n",
    "# Compute WER and CER \n",
    "base_wer = wer(base_actual_labels, base_generated_text)\n",
    "base_cer = cer(base_actual_labels, base_generated_text)\n",
    "\n",
    "finetuned_wer = wer(finetuned_actual_labels, finetuned_generated_text)\n",
    "finetuned_cer = cer(finetuned_actual_labels, finetuned_generated_text)\n",
    "\n",
    "# Prepare the comparison report\n",
    "comparison_report = pd.DataFrame({\n",
    "    \"Metric\": [\"Word Error Rate (WER)\", \"Character Error Rate (CER)\"],\n",
    "    \"Base Model\": [base_wer, base_cer],\n",
    "    \"Fine-Tuned Model\": [finetuned_wer, finetuned_cer],\n",
    "    \"Improvement\": [base_wer - finetuned_wer, base_cer - finetuned_cer]\n",
    "})\n",
    "\n",
    "comparison_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "#### Word Error Rate (WER)\n",
    "We can see that the WER improved by 0.0294 (2.94%) after finetuning the model. This is a significant improvement in the performance of the model, since the base model was already performing quite well. Relative to the base model, the fine-tuned model's performance increased by 27.2% ((0.108120 - 0.078751) / 0.108120).\n",
    "\n",
    "#### Character Error Rate (CER)\n",
    "The CER also improved  by 0.011427 (1.14%) after finetuning the model. This is a significant improvement, given that the base model has a very low CER of 0.045444. Relative to the base model, the fine-tuned model's performance increased by 25.1% ((0.045444 - 0.034017) / 0.045444)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "htx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
