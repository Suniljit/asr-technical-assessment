{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE! NEW ENVIRONMENT REQUIRED\n",
    "In Task 5B, we'll be using an embeddings model by installing the InstructorEmbedding library. This library and its requirements conflict the dependencies for the other tasks. Hence, we will use a seperate enviroment for this task. Below are the instructions:\n",
    "1. Create a new enviroment with Python 3.10: `conda create --name myenv2 python=3.10`\n",
    "2. Activate the enviroment: `conda activate myenv2`\n",
    "3. Install the following packages using conda forge:  \n",
    "`conda install -c conda-forge huggingface_hub=0.11.1 sentence-transformers==2.2.2 transformers==4.20.0 InstructorEmbedding pandas scikit-learn`\n",
    "\n",
    "### Note\n",
    "If you experience any issues during the installation with the tokenizer package, you will need to ensure that your device has rust installed. Follow the below steps to install it:\n",
    "1. Run the following command: `curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh`\n",
    "2. Add just to your environment path: `source $HOME/.cargo/env`\n",
    "3. Check that rust is installed: `rustc --version`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5B\n",
    "We will use an embeddings model to find similar phrases to the 3 hot words specified in the task. The hot words are \"be careful\", \"destroy\", and \"stranger\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/htx2/lib/python3.10/site-packages/InstructorEmbedding/instructor.py:7: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/htx2/lib/python3.10/site-packages/sentence_transformers/models/Dense.py:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(os.path.join(input_path, 'pytorch_model.bin'), map_location=torch.device('cpu')))\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained embedding model\n",
    "model = INSTRUCTOR('hkunlp/instructor-large')\n",
    "\n",
    "# Define hot words with a task-specific instruction\n",
    "hot_words = [\n",
    "    [\"Represent the hotword for similarity\", \"be careful\"],\n",
    "    [\"Represent the hotword for similarity\", \"destroy\"],\n",
    "    [\"Represent the hotword for similarity\", \"stranger\"]\n",
    "]\n",
    "\n",
    "# Embed the hot words\n",
    "hotword_embeddings = model.encode(hot_words)\n",
    "\n",
    "# Load cv-valid-dev.csv\n",
    "cv_valid_dev = pd.read_csv('../data/common_voice/cv-valid-dev.csv')\n",
    "\n",
    "# Define a function to compute the similarity for each text entry\n",
    "def compute_similarity(row_text):\n",
    "    instruction_text = [[\"Represent the text for similarity\", row_text]]\n",
    "    text_embedding = model.encode(instruction_text)\n",
    "    # Calculate cosine similarity with hotword embeddings\n",
    "    similarities = cosine_similarity(text_embedding, hotword_embeddings)\n",
    "    return similarities.max()  # Return the highest similarity score\n",
    "\n",
    "# Apply similarity computation\n",
    "cv_valid_dev['similarity_score'] = cv_valid_dev['text'].astype(str).apply(compute_similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify similarity based on a threshold\n",
    "threshold = 0.85\n",
    "cv_valid_dev['similarity'] = cv_valid_dev['similarity_score'] >= threshold\n",
    "\n",
    "# Save the updated DataFrame to a CSV\n",
    "cv_valid_dev.to_csv('similarity.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Through The Similiarity Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv-valid-dev/sample-000000.mp3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cv-valid-dev/sample-000003.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cv-valid-dev/sample-000089.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cv-valid-dev/sample-000508.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cv-valid-dev/sample-000674.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cv-valid-dev/sample-001093.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cv-valid-dev/sample-001101.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cv-valid-dev/sample-001243.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cv-valid-dev/sample-001501.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cv-valid-dev/sample-001933.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cv-valid-dev/sample-002405.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cv-valid-dev/sample-002453.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cv-valid-dev/sample-003065.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cv-valid-dev/sample-003219.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cv-valid-dev/sample-003808.mp3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cv-valid-dev/sample-000000.mp3\n",
       "0   cv-valid-dev/sample-000003.mp3\n",
       "1   cv-valid-dev/sample-000089.mp3\n",
       "2   cv-valid-dev/sample-000508.mp3\n",
       "3   cv-valid-dev/sample-000674.mp3\n",
       "4   cv-valid-dev/sample-001093.mp3\n",
       "5   cv-valid-dev/sample-001101.mp3\n",
       "6   cv-valid-dev/sample-001243.mp3\n",
       "7   cv-valid-dev/sample-001501.mp3\n",
       "8   cv-valid-dev/sample-001933.mp3\n",
       "9   cv-valid-dev/sample-002405.mp3\n",
       "10  cv-valid-dev/sample-002453.mp3\n",
       "11  cv-valid-dev/sample-003065.mp3\n",
       "12  cv-valid-dev/sample-003219.mp3\n",
       "13  cv-valid-dev/sample-003808.mp3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detected = pd.read_csv('detected.txt')\n",
    "detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accent</th>\n",
       "      <th>duration</th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cv-valid-dev/sample-000000.mp3</td>\n",
       "      <td>be careful with your prognostications said the...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.872691</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cv-valid-dev/sample-000001.mp3</td>\n",
       "      <td>then why should they be surprised when they se...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.823436</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cv-valid-dev/sample-000002.mp3</td>\n",
       "      <td>a young arab also loaded down with baggage ent...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785186</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cv-valid-dev/sample-000003.mp3</td>\n",
       "      <td>i thought that everything i owned would be des...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.817373</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cv-valid-dev/sample-000004.mp3</td>\n",
       "      <td>he moved about invisible but everyone could he...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>fourties</td>\n",
       "      <td>female</td>\n",
       "      <td>england</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.754095</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         filename  \\\n",
       "0  cv-valid-dev/sample-000000.mp3   \n",
       "1  cv-valid-dev/sample-000001.mp3   \n",
       "2  cv-valid-dev/sample-000002.mp3   \n",
       "3  cv-valid-dev/sample-000003.mp3   \n",
       "4  cv-valid-dev/sample-000004.mp3   \n",
       "\n",
       "                                                text  up_votes  down_votes  \\\n",
       "0  be careful with your prognostications said the...         1           0   \n",
       "1  then why should they be surprised when they se...         2           0   \n",
       "2  a young arab also loaded down with baggage ent...         2           0   \n",
       "3  i thought that everything i owned would be des...         3           0   \n",
       "4  he moved about invisible but everyone could he...         1           0   \n",
       "\n",
       "        age  gender   accent  duration  similarity_score  similarity  \n",
       "0       NaN     NaN      NaN       NaN          0.872691        True  \n",
       "1       NaN     NaN      NaN       NaN          0.823436       False  \n",
       "2       NaN     NaN      NaN       NaN          0.785186       False  \n",
       "3       NaN     NaN      NaN       NaN          0.817373       False  \n",
       "4  fourties  female  england       NaN          0.754095       False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar = pd.read_csv('similarity.csv')\n",
    "similar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       cv-valid-dev/sample-000000.mp3\n",
       "89      cv-valid-dev/sample-000089.mp3\n",
       "508     cv-valid-dev/sample-000508.mp3\n",
       "579     cv-valid-dev/sample-000579.mp3\n",
       "674     cv-valid-dev/sample-000674.mp3\n",
       "1093    cv-valid-dev/sample-001093.mp3\n",
       "1101    cv-valid-dev/sample-001101.mp3\n",
       "1115    cv-valid-dev/sample-001115.mp3\n",
       "1243    cv-valid-dev/sample-001243.mp3\n",
       "1501    cv-valid-dev/sample-001501.mp3\n",
       "1507    cv-valid-dev/sample-001507.mp3\n",
       "1717    cv-valid-dev/sample-001717.mp3\n",
       "1781    cv-valid-dev/sample-001781.mp3\n",
       "1828    cv-valid-dev/sample-001828.mp3\n",
       "1933    cv-valid-dev/sample-001933.mp3\n",
       "1978    cv-valid-dev/sample-001978.mp3\n",
       "2104    cv-valid-dev/sample-002104.mp3\n",
       "2120    cv-valid-dev/sample-002120.mp3\n",
       "2405    cv-valid-dev/sample-002405.mp3\n",
       "2410    cv-valid-dev/sample-002410.mp3\n",
       "2432    cv-valid-dev/sample-002432.mp3\n",
       "3127    cv-valid-dev/sample-003127.mp3\n",
       "3219    cv-valid-dev/sample-003219.mp3\n",
       "3245    cv-valid-dev/sample-003245.mp3\n",
       "3344    cv-valid-dev/sample-003344.mp3\n",
       "3808    cv-valid-dev/sample-003808.mp3\n",
       "3828    cv-valid-dev/sample-003828.mp3\n",
       "3898    cv-valid-dev/sample-003898.mp3\n",
       "Name: filename, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar.loc[similar['similarity'] == True]['filename']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By comparing the two files, we observe the following:\n",
    "- 12 of the 15 files in detected.txt were found in the similarity data.\n",
    "- 3 of the 15 files in detected.txt were not found in the similarity data.\n",
    "- 16 extra files, not found in detected.txt, were found in the similarity data. Looking through some of them, they have words that are similar to the hot words, which could be why they were included in the similarity data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "htx2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
